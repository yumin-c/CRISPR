{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler, SequentialSampler\n",
    "from torch.backends import cudnn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneInteractionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "        super(GeneInteractionModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=72,\n",
    "                      kernel_size=(2, 3), stride=1, padding=(0, 1)),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=72, out_channels=64,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=64,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=96,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.r = nn.GRU(96, hidden_size, num_layers,\n",
    "                        batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.s = nn.Linear(2 * hidden_size, 24, bias=False)\n",
    "        \n",
    "        self.d = nn.Sequential(\n",
    "            nn.Linear(27, 96, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(96, 32, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 64, bias=False)\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(88, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g = torch.squeeze(self.c1(g), 2)\n",
    "        g = self.c2(g)\n",
    "        g, _ = self.r(torch.transpose(g, 1, 2))\n",
    "        g = self.s(g[:, -1, :])\n",
    "        \n",
    "        x = self.d(x)\n",
    "\n",
    "        out = self.head(torch.cat((g, x), dim=1))\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneFeatureDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        gene: torch.Tensor = None,\n",
    "        features: torch.Tensor = None,\n",
    "        target: torch.Tensor = None,\n",
    "        fold: int = None,\n",
    "        mode: str = 'train',\n",
    "        fold_list: np.ndarray = None,\n",
    "    ):\n",
    "        self.fold = fold\n",
    "        self.mode = mode\n",
    "        self.fold_list = fold_list\n",
    "\n",
    "        if self.fold_list is not None:\n",
    "            self.indices = self._select_fold()\n",
    "            self.gene = gene[self.indices]\n",
    "            self.features = features[self.indices]\n",
    "            self.target = target[self.indices]\n",
    "        else:\n",
    "            self.gene = gene\n",
    "            self.features = features\n",
    "            self.target = target\n",
    "\n",
    "    def _select_fold(self):\n",
    "        selected_indices = []\n",
    "\n",
    "        if self.mode == 'valid':  # SELECT A SINGLE GROUP\n",
    "            for i in range(len(self.fold_list)):\n",
    "                if self.fold_list[i] == self.fold:\n",
    "                    selected_indices.append(i)\n",
    "        elif self.mode == 'train':  # SELECT OTHERS\n",
    "            for i in range(len(self.fold_list)):\n",
    "                if self.fold_list[i] != self.fold:\n",
    "                    selected_indices.append(i)\n",
    "        else:  # FOR FINALIZING\n",
    "            for i in range(len(self.fold_list)):\n",
    "                selected_indices.append(i)\n",
    "\n",
    "        return selected_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gene)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        gene = self.gene[idx]\n",
    "        features = self.features[idx]\n",
    "        target = self.target[idx]\n",
    "\n",
    "        return gene, features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq(data):\n",
    "    print(\"Start preprocessing the sequence done 2d\")\n",
    "    length = 74\n",
    "\n",
    "    DATA_X = np.zeros((len(data), 1, length, 4), dtype=float)\n",
    "    print(np.shape(data), len(data), length)\n",
    "    for l in tqdm(range(len(data))):\n",
    "        for i in range(length):\n",
    "\n",
    "            try:\n",
    "                data[l][i]\n",
    "            except:\n",
    "                print(data[l], i, length, len(data))\n",
    "\n",
    "            if data[l][i] in \"Aa\":\n",
    "                DATA_X[l, 0, i, 0] = 1\n",
    "            elif data[l][i] in \"Cc\":\n",
    "                DATA_X[l, 0, i, 1] = 1\n",
    "            elif data[l][i] in \"Gg\":\n",
    "                DATA_X[l, 0, i, 2] = 1\n",
    "            elif data[l][i] in \"Tt\":\n",
    "                DATA_X[l, 0, i, 3] = 1\n",
    "            elif data[l][i] in \"Xx\":\n",
    "                DATA_X[l, 0, i, 0] = 0.5\n",
    "                DATA_X[l, 0, i, 1] = 0.5\n",
    "                DATA_X[l, 0, i, 2] = 0.5\n",
    "                DATA_X[l, 0, i, 3] = 0.5\n",
    "            else:\n",
    "                print(\"Non-ATGC character \" + data[l])\n",
    "                print(i)\n",
    "                print(data[l][i])\n",
    "                sys.exit()\n",
    "\n",
    "    print(\"Preprocessed the sequence\")\n",
    "    return DATA_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_concat(data):\n",
    "    wt = preprocess_seq(data.WT74_On)\n",
    "    ed = preprocess_seq(data.Edited74_On)\n",
    "    g = np.concatenate((wt, ed), axis=1)\n",
    "    g = 2 * g - 1\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PECV = pd.read_csv('data/DeepPrime_PECV__train_220214.csv')\n",
    "test_PECV = pd.read_csv('data/DeepPrime_PECV__test_220214.csv')\n",
    "train_PF = pd.read_csv('data/DeepPrime_on_target_test_wProfiling_220209.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS GENES\n",
    "\n",
    "if not os.path.isfile('data/g_train.npy'):\n",
    "    g_train = seq_concat(train_PECV)\n",
    "    np.save('data/g_train.npy', g_train)\n",
    "else:\n",
    "    g_train = np.load('data/g_train.npy')\n",
    "\n",
    "if not os.path.isfile('data/g_test.npy'):\n",
    "    g_test = seq_concat(test_PECV)\n",
    "    np.save('data/g_test.npy', g_test)\n",
    "else:\n",
    "    g_test = np.load('data/g_test.npy')\n",
    "\n",
    "if not os.path.isfile('data/g_pf.npy'):\n",
    "    g_pf = seq_concat(train_PF)\n",
    "    np.save('data/g_pf.npy', g_pf)\n",
    "else:\n",
    "    g_pf = np.load('data/g_pf.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SELECTION\n",
    "\n",
    "train_features = train_PECV.loc[:, ['PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len', 'type_sub',\n",
    "                                    'type_ins', 'type_del', 'Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n",
    "                                    'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3',\n",
    "                                    'MFE1', 'MFE2', 'MFE3', 'MFE4', 'MFE5', 'DeepSpCas9_score']]\n",
    "train_fold = train_PECV.Fold\n",
    "train_target = train_PECV.Measured_PE_efficiency\n",
    "\n",
    "test_features = test_PECV.loc[:, ['PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len', 'type_sub',\n",
    "                                  'type_ins', 'type_del', 'Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n",
    "                                  'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3',\n",
    "                                  'MFE1', 'MFE2', 'MFE3', 'MFE4', 'MFE5', 'DeepSpCas9_score']]\n",
    "test_target = test_PECV.Measured_PE_efficiency\n",
    "\n",
    "pf_features = train_PF.loc[:, ['PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len', 'type_sub',\n",
    "                               'type_ins', 'type_del', 'Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n",
    "                               'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3',\n",
    "                               'MFE1', 'MFE2', 'MFE3', 'MFE4', 'MFE5', 'DeepSpCas9_score']]\n",
    "pf_target = train_PF.Measured_PE_efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "\n",
    "x_train = (train_features - train_features.mean()) / train_features.std()\n",
    "y_train = (train_target - train_target.mean()) / train_target.std()\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "x_test = (test_features - train_features.mean()) / train_features.std()\n",
    "y_test = (test_target - train_target.mean()) / train_target.std()\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "x_pf = (pf_features - train_features.mean()) / train_features.std()\n",
    "y_pf = (pf_target - train_target.mean()) / train_target.std()\n",
    "x_pf = x_pf.to_numpy()\n",
    "y_pf = y_pf.to_numpy()\n",
    "\n",
    "g_train = torch.tensor(g_train, dtype=torch.float32, device=device)\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "\n",
    "g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "g_pf = torch.tensor(g_pf, dtype=torch.float32, device=device)\n",
    "x_pf = torch.tensor(x_pf, dtype=torch.float32, device=device)\n",
    "y_pf = torch.tensor(y_pf, dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "batch_size = 2048\n",
    "learning_rate = 4e-3\n",
    "weight_decay = 1e-2\n",
    "T_0 = 12\n",
    "T_mult = 1\n",
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "n_epochs = 10\n",
    "n_models = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model, fold, pf_loader, valid_loader):\n",
    "\n",
    "    # PARAMETERS FOR FINETUNING\n",
    "\n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 1e-3\n",
    "    T_0 = 5\n",
    "    T_mult = 1\n",
    "    n_epochs = 5\n",
    "\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad and name.startswith('c') or name.startswith('r'):\n",
    "    #         param.requires_grad = False # LOCK THE GENE ABSTRACTION MODULE\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=T_0, T_mult=T_mult, eta_min=learning_rate/100)\n",
    "\n",
    "    n_iters = len(pf_loader)\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss, valid_loss = [], []\n",
    "        train_count, valid_count = 0, 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (g, x, y) in enumerate(pf_loader):\n",
    "            g = torch.permute(g, (0, 3, 1, 2))\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "            pred = model(g, x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + i / n_iters)\n",
    "\n",
    "            train_loss.append(x.size(0) * loss.detach().cpu().numpy())\n",
    "            train_count += x.size(0)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        pred_, y_ = None, None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (g, x, y) in enumerate(valid_loader):\n",
    "                g = torch.permute(g, (0, 3, 1, 2))\n",
    "                y = y.reshape(-1, 1)\n",
    "\n",
    "                pred = model(g, x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                valid_loss.append(x.size(0) * loss.detach().cpu().numpy())\n",
    "                valid_count += x.size(0)\n",
    "\n",
    "                if pred_ is None:\n",
    "                    pred_ = pred.detach().cpu().numpy()\n",
    "                    y_ = y.detach().cpu().numpy()\n",
    "                else:\n",
    "                    pred_ = np.concatenate(\n",
    "                        (pred_, pred.detach().cpu().numpy()))\n",
    "                    y_ = np.concatenate((y_, y.detach().cpu().numpy()))\n",
    "\n",
    "        train_loss = sum(train_loss) / train_count\n",
    "        valid_loss = sum(valid_loss) / valid_count\n",
    "\n",
    "        SPR = scipy.stats.spearmanr(pred_, y_).correlation\n",
    "\n",
    "        print('FINETUNING: [FOLD {:02}/{:02}] [E {:03}/{:03}] : {:.4f} | {:.4f} | {:.4f}'.format(\n",
    "            fold + 1, 5, epoch + 1, n_epochs, train_loss, valid_loss, SPR))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:30,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 001/010] : 0.7719 | 0.6546 | 0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:06<00:24,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 002/010] : 0.6669 | 0.5923 | 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:09<00:21,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 003/010] : 0.5929 | 0.5261 | 0.7124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:12<00:18,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 004/010] : 0.5139 | 0.4610 | 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:15<00:15,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 005/010] : 0.4545 | 0.4436 | 0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:18<00:12,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 006/010] : 0.4182 | 0.4366 | 0.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:22<00:09,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 007/010] : 0.3900 | 0.4193 | 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:25<00:06,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 008/010] : 0.3677 | 0.4155 | 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:29<00:03,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 009/010] : 0.3525 | 0.4144 | 0.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 01/05] [M 001/001] [E 010/010] : 0.3360 | 0.4268 | 0.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:03<00:34,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 001/010] : 0.7597 | 0.6339 | 0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:07<00:30,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 002/010] : 0.6457 | 0.5795 | 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:11<00:26,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 003/010] : 0.5718 | 0.5208 | 0.7124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:15<00:23,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 004/010] : 0.5124 | 0.4764 | 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:19<00:19,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 005/010] : 0.4563 | 0.4485 | 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:23<00:15,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 006/010] : 0.4201 | 0.4380 | 0.7516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:27<00:11,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 007/010] : 0.3920 | 0.4202 | 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:31<00:07,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 008/010] : 0.3715 | 0.4275 | 0.7581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:34<00:03,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 009/010] : 0.3531 | 0.4211 | 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:38<00:00,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 02/05] [M 001/001] [E 010/010] : 0.3387 | 0.4194 | 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:03<00:34,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 001/010] : 0.7646 | 0.6602 | 0.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:07<00:30,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 002/010] : 0.6592 | 0.5904 | 0.6916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:10<00:24,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 003/010] : 0.5661 | 0.5083 | 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:13<00:19,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 004/010] : 0.4872 | 0.4548 | 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:16<00:16,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 005/010] : 0.4365 | 0.4404 | 0.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:19<00:12,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 006/010] : 0.4006 | 0.4325 | 0.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:23<00:09,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 007/010] : 0.3760 | 0.4249 | 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:26<00:06,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 008/010] : 0.3523 | 0.4220 | 0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:29<00:03,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 009/010] : 0.3334 | 0.4250 | 0.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 03/05] [M 001/001] [E 010/010] : 0.3196 | 0.4221 | 0.7663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:03<00:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 001/010] : 0.7557 | 0.7025 | 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:07<00:30,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 002/010] : 0.6490 | 0.6281 | 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:11<00:26,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 003/010] : 0.5720 | 0.5585 | 0.7172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:15<00:22,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 004/010] : 0.5072 | 0.5207 | 0.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:19<00:19,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 005/010] : 0.4475 | 0.4736 | 0.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:23<00:15,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 006/010] : 0.4090 | 0.4606 | 0.7631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:26<00:11,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 007/010] : 0.3826 | 0.4510 | 0.7735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:30<00:07,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 008/010] : 0.3578 | 0.4524 | 0.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:34<00:03,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 009/010] : 0.3413 | 0.4427 | 0.7758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:38<00:00,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 04/05] [M 001/001] [E 010/010] : 0.3272 | 0.4441 | 0.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:04<00:37,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 001/010] : 0.7677 | 0.5695 | 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:08<00:32,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 002/010] : 0.6518 | 0.5017 | 0.6670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:12<00:28,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 003/010] : 0.5596 | 0.4485 | 0.6862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:15<00:23,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 004/010] : 0.4889 | 0.4164 | 0.6972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:18<00:18,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 005/010] : 0.4360 | 0.3970 | 0.7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:22<00:13,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 006/010] : 0.4071 | 0.3858 | 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:25<00:10,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 007/010] : 0.3821 | 0.3835 | 0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:28<00:06,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 008/010] : 0.3616 | 0.3823 | 0.7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:31<00:03,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 009/010] : 0.3453 | 0.3899 | 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FOLD 05/05] [M 001/001] [E 010/010] : 0.3324 | 0.3775 | 0.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING & VALIDATION\n",
    "# preds = np.zeros((n_models, test_y.size(0)))\n",
    "\n",
    "for m in range(n_models):\n",
    "\n",
    "    random_seed = m\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for fold in range(5):\n",
    "\n",
    "        best_score = [0, 0, 0]\n",
    "\n",
    "        model = GeneInteractionModel(\n",
    "            hidden_size=hidden_size, num_layers=n_layers).to(device)\n",
    "\n",
    "        train_set = GeneFeatureDataset(\n",
    "            g_train, x_train, y_train, fold, 'train', train_fold)\n",
    "        valid_set = GeneFeatureDataset(\n",
    "            g_train, x_train, y_train, fold, 'valid', train_fold)\n",
    "        pf_set = GeneFeatureDataset(g_pf, x_pf, y_pf, None, 'train', None)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        pf_loader = DataLoader(\n",
    "            dataset=pf_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=T_0, T_mult=T_mult, eta_min=learning_rate/100)\n",
    "\n",
    "        n_iters = len(train_loader)\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            train_loss, valid_loss = [], []\n",
    "            train_count, valid_count = 0, 0\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for i, (g, x, y) in enumerate(train_loader):\n",
    "                g = torch.permute(g, (0, 3, 1, 2))\n",
    "                y = y.reshape(-1, 1)\n",
    "\n",
    "                pred = model(g, x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + i / n_iters)\n",
    "\n",
    "                train_loss.append(x.size(0) * loss.detach().cpu().numpy())\n",
    "                train_count += x.size(0)\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            pred_, y_ = None, None\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, (g, x, y) in enumerate(valid_loader):\n",
    "                    g = torch.permute(g, (0, 3, 1, 2))\n",
    "                    y = y.reshape(-1, 1)\n",
    "\n",
    "                    pred = model(g, x)\n",
    "                    loss = criterion(pred, y)\n",
    "\n",
    "                    valid_loss.append(x.size(0) * loss.detach().cpu().numpy())\n",
    "                    valid_count += x.size(0)\n",
    "\n",
    "                    if pred_ is None:\n",
    "                        pred_ = pred.detach().cpu().numpy()\n",
    "                        y_ = y.detach().cpu().numpy()\n",
    "                    else:\n",
    "                        pred_ = np.concatenate(\n",
    "                            (pred_, pred.detach().cpu().numpy()))\n",
    "                        y_ = np.concatenate((y_, y.detach().cpu().numpy()))\n",
    "\n",
    "            train_loss = sum(train_loss) / train_count\n",
    "            valid_loss = sum(valid_loss) / valid_count\n",
    "\n",
    "            SPR = scipy.stats.spearmanr(pred_, y_).correlation\n",
    "\n",
    "            if SPR > best_score[2]:\n",
    "                best_score = [train_loss, valid_loss, SPR]\n",
    "\n",
    "                torch.save(model.state_dict(), 'models/F{:02}_auxiliary.pt'.format(fold + 1))\n",
    "\n",
    "\n",
    "            print('[FOLD {:02}/{:02}] [M {:03}/{:03}] [E {:03}/{:03}] : {:.4f} | {:.4f} | {:.4f}'.format(fold + 1, 5, m + 1,\n",
    "                                                                                                         n_models, epoch + 1, n_epochs, train_loss, valid_loss, SPR))\n",
    "        \n",
    "        os.rename('models/F{:02}_auxiliary.pt'.format(fold + 1), 'models/F{:02}_T{:.4f}_V{:.4f}_S{:.4f}.pt'.format(fold + 1, *best_score))\n",
    "\n",
    "        # finetune_model(model, fold, pf_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 01/05] [E 001/005] : 0.9097 | 0.4304 | 0.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:03,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 01/05] [E 002/005] : 0.8847 | 0.4297 | 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:03<00:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 01/05] [E 003/005] : 0.8795 | 0.4299 | 0.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:05<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 01/05] [E 004/005] : 0.8728 | 0.4298 | 0.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 01/05] [E 005/005] : 0.8705 | 0.4301 | 0.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 02/05] [E 001/005] : 0.9090 | 0.4360 | 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 02/05] [E 002/005] : 0.8761 | 0.4362 | 0.7723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:03<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 02/05] [E 003/005] : 0.8612 | 0.4352 | 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:04<00:01,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 02/05] [E 004/005] : 0.8545 | 0.4358 | 0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 02/05] [E 005/005] : 0.8562 | 0.4358 | 0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 03/05] [E 001/005] : 0.9376 | 0.4385 | 0.7688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 03/05] [E 002/005] : 0.9048 | 0.4405 | 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:03<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 03/05] [E 003/005] : 0.8887 | 0.4407 | 0.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:04<00:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 03/05] [E 004/005] : 0.8828 | 0.4406 | 0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 03/05] [E 005/005] : 0.8779 | 0.4408 | 0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 04/05] [E 001/005] : 0.9010 | 0.4489 | 0.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:03,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 04/05] [E 002/005] : 0.8758 | 0.4498 | 0.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:03<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 04/05] [E 003/005] : 0.8641 | 0.4494 | 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:04<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 04/05] [E 004/005] : 0.8557 | 0.4498 | 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 04/05] [E 005/005] : 0.8548 | 0.4497 | 0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:03,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 05/05] [E 001/005] : 0.9404 | 0.3903 | 0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 05/05] [E 002/005] : 0.9041 | 0.3939 | 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:02<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 05/05] [E 003/005] : 0.8960 | 0.3931 | 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:03<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 05/05] [E 004/005] : 0.8843 | 0.3934 | 0.7331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINETUNING: [FOLD 05/05] [E 005/005] : 0.8854 | 0.3934 | 0.7332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL FINE TUNING\n",
    "\n",
    "models = ['models/F01_T0.3677_V0.4155_S0.7734.pt', 'models/F02_T0.3387_V0.4194_S0.7697.pt',\n",
    "          'models/F03_T0.3196_V0.4221_S0.7663.pt', 'models/F04_T0.3413_V0.4427_S0.7758.pt', 'models/F05_T0.3821_V0.3835_S0.7311.pt']\n",
    "\n",
    "pf_set = GeneFeatureDataset(g_pf, x_pf, y_pf, None, 'train', None)\n",
    "pf_loader = DataLoader(\n",
    "    dataset=pf_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "for fold in range(5):\n",
    "    valid_set = GeneFeatureDataset(\n",
    "        g_train, x_train, y_train, fold, 'valid', train_fold)\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = GeneInteractionModel(\n",
    "            hidden_size=hidden_size, num_layers=n_layers).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(models[fold]))\n",
    "\n",
    "    model = finetune_model(model, fold, pf_loader, valid_loader)\n",
    "\n",
    "    torch.save(model.state_dict(), 'models/final/F{:02}.pt'.format(fold + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417406100357016\n"
     ]
    }
   ],
   "source": [
    "test_set = GeneFeatureDataset(g_test, x_test, y_test)\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for fold in range(5):\n",
    "    model = GeneInteractionModel(\n",
    "        hidden_size=hidden_size, num_layers=n_layers).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load('models/final/F{:02}.pt'.format(fold + 1)))\n",
    "\n",
    "    pred_, y_ = None, None\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (g, x, y) in enumerate(test_loader):\n",
    "            g = torch.permute(g, (0, 3, 1, 2))\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "            pred = model(g, x)\n",
    "\n",
    "            if pred_ is None:\n",
    "                pred_ = pred.detach().cpu().numpy()\n",
    "                y_ = y.detach().cpu().numpy()\n",
    "            else:\n",
    "                pred_ = np.concatenate(\n",
    "                    (pred_, pred.detach().cpu().numpy()))\n",
    "                y_ = np.concatenate((y_, y.detach().cpu().numpy()))\n",
    "    \n",
    "    preds.append(pred_)\n",
    "    SPR = scipy.stats.spearmanr(pred_, y_).correlation\n",
    "\n",
    "preds = np.squeeze(np.array(preds))\n",
    "preds = np.mean(preds, axis=0)\n",
    "\n",
    "print(scipy.stats.spearmanr(preds, y_).correlation)\n",
    "\n",
    "preds = preds * train_target.std() + train_target.mean()\n",
    "y_ = y_ * train_target.std() + train_target.mean()\n",
    "\n",
    "preds = pd.DataFrame(preds, columns=['Predicted PE efficiency'])\n",
    "preds.to_csv('results/220218.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.scatter(y_, preds, s=0.1)\n",
    "ax.set_xlim([-1, 31])\n",
    "ax.set_ylim([-1, 31])\n",
    "ax.set_xticks(range(0, 35, 5))\n",
    "ax.set_yticks(range(0, 35, 5))\n",
    "\n",
    "ax.set_title(\"Evaluation of DeepPE2\")\n",
    "ax.set_xlabel(\"Measured PE2 efficiency (%)\")\n",
    "ax.set_ylabel(\"DeepPE prediction score (%)\")\n",
    "\n",
    "ax.annotate('R = 0.84174',\n",
    "            xy=(1, 0), xycoords='axes fraction',\n",
    "            xytext=(-20, 20), textcoords='offset pixels',\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='bottom')\n",
    "\n",
    "plt.savefig('Evaluation of DeepPE2.jpg', bbox_inches=\"tight\", dpi=600)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a7613cd914eed0861a71d3563e174029307b7234eceeeb943f9e4e2446ab66f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gene')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
